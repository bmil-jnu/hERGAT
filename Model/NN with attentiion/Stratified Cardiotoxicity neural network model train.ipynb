{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174793d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 09:48:52.692663: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-26 09:48:52.692723: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-26 09:48:52.698490: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-26 09:48:52.713116: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-26 09:48:54.089827: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/tmp/ipykernel_2159038/651580031.py:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import kerastuner\n",
    "import tensorflow\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "from scipy import interp\n",
    "from tensorflow.keras.layers import Embedding, Dense \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d51632-2844-4b96-a963-9d3e855a64f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/home/ldhyun7222/hERGAT/NN with self-attention'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7bb3d4-3e3b-4666-9014-92fff547e4a1",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d719e1bb-3fd1-463b-ab1f-96e968d0564f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9238, 1029)\n",
      "(9238,)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train_df2.csv')\n",
    "test_df = pd.read_csv('test_df2.csv')\n",
    "\n",
    "train_df = train_df.drop(columns = ['SMILES', 'cano_smiles'])\n",
    "test_df = test_df.drop(columns = ['SMILES', 'cano_smiles'])\n",
    "\n",
    "x_train = train_df.drop(columns = 'Class')\n",
    "x_test = test_df.drop(columns = 'Class')\n",
    "\n",
    "y_train = train_df['Class']\n",
    "y_test = test_df['Class']\n",
    "\n",
    "X_df = pd.concat([train_df, test_df], axis = 0)\n",
    "X_df = X_df.reset_index().drop(columns = 'index')\n",
    "X = X_df.drop(columns = 'Class')\n",
    "y = X_df['Class']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d4cded3-e25b-443f-a71b-8f864419b1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data의 차원 수\n",
    "input_dim = x_train.shape[1]\n",
    "\n",
    "# Layer weight initializers 설정 (가중치 초기화 설정)\n",
    "initializer = tf.keras.initializers.HeNormal()\n",
    "\n",
    "\n",
    "# L2 regularizer 설정\n",
    "from tensorflow.keras import regularizers\n",
    "regularizer = regularizers.l2(0.001)\n",
    "\n",
    "#model hyperparameter\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "#callbacks\n",
    "callbacks = [\n",
    "    tensorflow.keras.callbacks.ModelCheckpoint(\n",
    "        \"hERGattention.h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    tensorflow.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=30, verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da28edac-5002-470d-a91d-dd3a1d5f2033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 1029)]               0         []                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1029)                 1059870   ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " softmax (Softmax)           (None, 1029)                 0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (None, 1029)                 0         ['input_1[0][0]',             \n",
      " da)                                                                 'softmax[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 512)                  527360    ['tf.math.multiply[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 512)                  2048      ['dense_1[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 512)                  0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 256)                  131328    ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 256)                  1024      ['dense_2[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 16)                   4112      ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 16)                   64        ['dense_3[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 1)                    17        ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1725823 (6.58 MB)\n",
      "Trainable params: 1724255 (6.58 MB)\n",
      "Non-trainable params: 1568 (6.12 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 09:49:02.205221: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/data/home/bmi-lab/anaconda3/envs/dohyeon/lib/python3.9/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# PregTaboo\n",
    "from keras.layers import Dense, Dropout, MultiHeadAttention\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# 모델 세부 설정\n",
    "inputs = tf.keras.layers.Input(shape=(input_dim,))\n",
    "\n",
    "dense_v = tf.keras.layers.Dense(input_dim, activation = None)(inputs)\n",
    "attn_score = tf.keras.layers.Softmax(axis = -1)(dense_v)\n",
    "cal_score = tf.math.multiply(inputs, attn_score)\n",
    "\n",
    "Dense1 = tf.keras.layers.Dense(512, activation = 'relu',kernel_initializer = initializer)(cal_score)\n",
    "Dense1_BN = tf.keras.layers.BatchNormalization()(Dense1)\n",
    "Dropout = Dropout(rate=0.25)(Dense1_BN)\n",
    "\n",
    "Dense2 = tf.keras.layers.Dense(256, activation = 'relu', kernel_initializer = initializer, kernel_regularizer=regularizer)(Dropout)\n",
    "Dense2_BN = tf.keras.layers.BatchNormalization()(Dense2)\n",
    "Dense3 = tf.keras.layers.Dense(16, activation = 'relu', kernel_initializer = initializer, kernel_regularizer=regularizer)(Dense2_BN)\n",
    "Dense3_BN = tf.keras.layers.BatchNormalization()(Dense3)\n",
    "outputs = tf.keras.layers.Dense(1, activation = 'sigmoid')(Dense3_BN)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "930e8c89-ad39-4f39-ba2b-b9eaaa2efc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755ba811-5369-47fa-9814-8e852a91e20e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score, auc, precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "# 점수를 저장할 리스트 초기화\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "roc_scores = [] \n",
    "pr_aucs = []\n",
    "f1_scores = []\n",
    "\n",
    "# 그래프 준비\n",
    "tpr_list = []\n",
    "fpr_list = []\n",
    "roc_auc_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "pr_auc_list = []\n",
    "\n",
    "# 10겹 계층화 교차 검증 설정\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # 모델정의\n",
    "    dense_v = tf.keras.layers.Dense(input_dim, activation=None, kernel_initializer=tf.keras.initializers.HeNormal(seed=42))(inputs)\n",
    "    attn_score = tf.keras.layers.Softmax(axis=-1)(dense_v)\n",
    "    cal_score = tf.math.multiply(inputs, attn_score)\n",
    "    \n",
    "    Dense1 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.HeNormal(seed=42))(cal_score)\n",
    "    Dense1_BN = tf.keras.layers.BatchNormalization()(Dense1)\n",
    "    Dropout_layer = tf.keras.layers.Dropout(rate=0.25)(Dense1_BN)  # 이름 변경\n",
    "    \n",
    "    Dense2 = tf.keras.layers.Dense(256, activation='relu', kernel_initializer=tf.keras.initializers.HeNormal(seed=42), kernel_regularizer=regularizer)(Dropout_layer)\n",
    "    Dense2_BN = tf.keras.layers.BatchNormalization()(Dense2)\n",
    "    \n",
    "    Dense3 = tf.keras.layers.Dense(16, activation='relu', kernel_initializer=tf.keras.initializers.HeNormal(seed=42), kernel_regularizer=regularizer)(Dense2_BN)\n",
    "    Dense3_BN = tf.keras.layers.BatchNormalization()(Dense3)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(Dense3_BN)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "    # 모델 compile\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999), loss=\"binary_crossentropy\", metrics=[\"accuracy\"],)\n",
    "    \n",
    "   # 모델 학습\n",
    "    history = model.fit(X_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(X_test, y_test),callbacks=callbacks)\n",
    "    \n",
    "    # 테스트 셋 예측\n",
    "    test_preds = model.predict(X_test)\n",
    "    test_preds[test_preds >= 0.5] = 1\n",
    "    test_preds[test_preds < 0.5] = 0\n",
    "\n",
    "    # 점수 계산\n",
    "    accuracies.append(accuracy_score(y_test, test_preds))\n",
    "    precisions.append(precision_score(y_test, test_preds))\n",
    "    recalls.append(recall_score(y_test, test_preds))\n",
    "    roc_scores.append(roc_auc_score(y_test, model.predict(X_test)))\n",
    "\n",
    "    pr_precision, pr_recall, _ = precision_recall_curve(y_test, test_preds)\n",
    "    pr_aucs.append(auc(pr_recall, pr_precision))\n",
    "\n",
    "    f1_scores.append(2 * (precisions[-1] * recalls[-1]) / (precisions[-1] + recalls[-1]))\n",
    "\n",
    "    # AUROC 계산을 위한 값 저장\n",
    "    y_pred_proba = model.predict(X_test).ravel()\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    tpr_list.append(tpr)\n",
    "    fpr_list.append(fpr)\n",
    "    roc_auc_list.append(roc_auc)\n",
    "\n",
    "    # AUPR 계산을 위한 값 저장\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    pr_auc_list.append(pr_auc)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a7ca0f-f2a6-4a88-bf09-75de29bf1146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 평가 지표에 대한 평균 계산\n",
    "print('Average Accuracy:', np.mean(accuracies))\n",
    "print('Average Precision:', np.mean(precisions))\n",
    "print('Average Recall/Sensitivity:', np.mean(recalls))\n",
    "print('Average ROC AUC Score:', np.mean(roc_scores))\n",
    "print('Average PR AUC:', np.mean(pr_aucs))\n",
    "print('Average F1 Score:', np.mean(f1_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cafc63-4724-42c3-b74c-3a7f36aad279",
   "metadata": {},
   "source": [
    "<nn with self-attention 성능평가>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b7da34-edb6-4c1c-b453-9a64735c58d6",
   "metadata": {},
   "source": [
    "# Stratified 10-cross validation AUROC 그래프 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decaeab4-cbf1-4166-b7d3-18f16f0ba4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(fpr_list)):\n",
    "    plt.plot(fpr_list[i], tpr_list[i], lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.3f)' % (i, roc_auc_list[i]))\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Stratified NN with attention_AUROC.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d54786-f6c3-4168-b6b4-7d5f7fbd195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 평균 TPR 및 평균 AUC 계산\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr_list = []\n",
    "\n",
    "for i in range(len(tpr_list)):\n",
    "    mean_tpr_list.append(interp(mean_fpr, fpr_list[i], tpr_list[i]))\n",
    "    \n",
    "mean_tpr = np.mean(mean_tpr_list, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "\n",
    "std_tpr = np.std(mean_tpr_list, axis = 0)\n",
    "\n",
    "# 평균 ROC Curve 그리기\n",
    "plt.figure()\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label=r'Mean NN_ROC (AUC = %0.3f)' % mean_auc, lw=2, alpha=.8)\n",
    "plt.fill_between(mean_fpr, mean_tpr - std_tpr, mean_tpr + std_tpr, color='grey', alpha=0.2, label=r'$\\pm$ 1 std. dev.')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=.8)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b62a8e5-9a77-4713-a75a-df179f7fd83d",
   "metadata": {},
   "source": [
    "# 각 fold별로 AUPR Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7d68cb-b90a-47d6-b38a-59a074c9c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(len(precision_list)):\n",
    "    plt.plot(recall_list[i], precision_list[i], lw=2, alpha=0.3, label='PR fold %d (AUC = %0.3f)' % (i+1, pr_auc_list[i]))\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.savefig('Stratified NN with attention_AUPR.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259549e4-a838-4248-b298-417fea7f059c",
   "metadata": {},
   "source": [
    "### 평균값으로 AUPR 그래프 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90a465f-d5df-4daf-aad7-30368f5c956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# 공통 recall 값 설정\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "mean_pr_auc = np.mean(pr_auc_list)\n",
    "\n",
    "# 각 fold의 precision 값을 공통 recall 값에 대해 보간\n",
    "interp_precision_list = []\n",
    "for precision, recall in zip(precision_list, recall_list):\n",
    "    # Interpolation 함수 생성\n",
    "    interp_func = interp1d(recall, precision, kind='linear', bounds_error=False, fill_value=(precision[0], precision[-1]))\n",
    "    # 공통 recall 값에 대해 precision 값을 보간\n",
    "    interp_precision = interp_func(mean_recall)\n",
    "    interp_precision_list.append(interp_precision)\n",
    "\n",
    "# 보간된 precision 값의 평균 계산\n",
    "mean_precision = np.mean(interp_precision_list, axis=0)\n",
    "std_precision = np.std(interp_precision_list, axis=0)\n",
    "\n",
    "# 평균 PR Curve 그리기\n",
    "plt.figure()\n",
    "plt.plot(mean_recall, mean_precision, label='Mean PR (AUC = {:.3f})'.format(mean_pr_auc), lw=2, alpha=.8)\n",
    "plt.fill_between(mean_recall, mean_precision - std_precision, mean_precision + std_precision, color='gray', alpha=0.2, label='Std Deviation')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.ylim([0.0, 1.0])\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e67124-dfdf-4261-865f-cdfda0321533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('../cross validation figure/Stratified 10-cross validation/nn_with_attention_mean_fpr.csv', mean_fpr, delimiter=',')\n",
    "# np.savetxt('../cross validation figure/Stratified 10-cross validation/nn_with_attention_mean_tpr.csv', mean_tpr, delimiter=',')\n",
    "# np.savetxt('../cross validation figure/Stratified 10-cross validation/nn_with_attention_mean_precision.csv', mean_precision, delimiter=',')\n",
    "# np.savetxt('../cross validation figure/Stratified 10-cross validation/nn_with_attention_mean_recall.csv', mean_recall, delimiter=',')\n",
    "\n",
    "\n",
    "\n",
    "# np.savetxt('../cross validation figure/Stratified 10-cross validation/nn_with_attention_std_tpr.csv', std_tpr, delimiter=',')\n",
    "# np.savetxt('../cross validation figure/Stratified 10-cross validation/nn_with_attention_std_precision.csv', std_precision, delimiter=',')\n",
    "# np.savetxt('../cross validation figure/Stratified 10-cross validation/nn_with_attention_pr_auc_list.csv', pr_auc_list, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171d9d69-0872-4a3b-bfdd-87f9993c66bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dec15e-1652-40aa-a1dd-4338e6660c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95f5f0e-798d-44f3-af45-6a56cf7e9210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1383717d-4a9c-41ef-8486-761669c2e8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0592d3-2c96-46e1-abfd-037c7df630fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3115676b-9c9a-44d5-859b-86c06e842911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986bda80-9a0e-408a-9ad3-a6fde7f54e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python dohyeon",
   "language": "python",
   "name": "dohyeon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
